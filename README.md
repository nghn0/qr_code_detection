# QR Code Detection

This repository provides the full implementation for training and running inference with a YOLOv8 model designed to detect QR codes within images.

The workflow covers dataset preparation and splitting, model training, and inference on unseen images, producing bounding box outputs in both visualized images and a JSON format file.

---

## 📂 Project Structure  

```
├── QR_Dataset/
│   ├── labels/
│      ├── img001.txt
│      ├── img002.txt
│      ├── ...
│      └── Annotation text files in YOLO format for each image in the train_images subset of QR_Dataset.
│   ├── train_images/        # Training images
│   ├── test_images/         # Test images for inference
│   ├── split2/  
│         ├── labels/              # YOLO format label files (.txt) with split of 80% training and 20% validation. Generated by running train.py
│         │   ├── train/
│         │   └── val/
│         ├── images/              #split of 80% training and 20% validation from the train_images in QR_Dataset. Generated by running train.py
│         │   ├── train/
│         │   └── val/
│   └── data.yaml            # Auto-generated by running train.py
│
├── src/
│   └── model/               # YOLO training outputs (weights, logs)
│
├── outputs/
│   ├── annotated_output/        # Annotated inference images
│   └── submission_detection_1.json      # Final detection results
│
├── splitting.py             # Splitting script
├── train.py                 # Training script
├── infer.py                 # Inference script
├── requirements.txt
└── README.md                # Project documentation

```
---

## ⚙️ Environment Setup 

### 1️⃣ Install requirements.txt  
```bash
pip install -r requirements.txt
```

### 2️⃣ Install dependencies  
```bash
pip install ultralytics
```
## Manual annotation of training images in QR_Dataset

### 1. Install Label Studio
Open a terminal and run:
```bash
pip install label-studio
````
### 2. Start Label Studio
Launch the tool with:
```bash
label-studio start
````

### 3. Upload Images
- After Label Studio opens in your browser, create a new project.
- Upload all images from your dataset.

### 4. Create Custom Labels
- Add a custom label (e.g., "QR Code") for annotating bounding boxes.

### 5. Annotate Images
- Open each image in the project.
- Draw bounding boxes around all QR codes present in the image.
- Save each annotation.

### 6. Export Annotations in YOLO Format
- After completing all annotations, export them in YOLO format (```.txt``` files).
- Each image should have a corresponding ```.txt``` annotation file.
> [!IMPORTANT]  
> The ```.txt``` file name must match the image file name.
> Example
> ```bash
> Image: train_images/img001.jpg
> Annotation: labels/img001.txt
> ```

> [!NOTE]  
> Only a few images are included in labels and QR_Dataset folder to show the folder structure. During the execution of ``train.py`` on Original QR_Dataset you will get the folder structure specified earlier


## 🚀 Training  

Run the training script to prepare the dataset and train YOLOv8:  

```bash
python train.py
```

This will:  
- Split your dataset into train/val  
- Generate `data.yaml`  
- Train YOLOv8 for 50 epochs  
- Save the best model in `src/model/qr_yolo_model_aug/weights/best.pt`  

### Original structure of dataset before running train.py

```
├── QR_Dataset/
   ├── train_images/        # Training images
   ├── test_images/         # Test images for inference
```

### Structure of dataset after running train.py

```
├── QR_Dataset/
   ├── train_images/        # Training images
   ├── test_images/         # Test images for inference
   ├── labels/              # YOLO format label files (.txt) with split of 80% training and 20% validation. Generated by running train.py
   │   ├── train/
   │   └── val/
   ├── images/              #split of 80% training and 20% validation from the train_images in QR_Dataset. Generated by running train.py
   │   ├── train/
   │   └── val/
   └── data.yaml            # Auto-generated by running train.py
```

---

## 🔎 Inference  

Run inference on a folder of test images:  

```bash
python infer.py
```
> [!NOTE]  
> In the ```infer.py``` script, update the line
> ```bash
> IMAGES_FOLDER = "QR_Dataset/test_images"
> ```
> to your own custom folder path. This tells the code where to look for images, and the output (annotated images and JSON) will be generated based on the images inside that folder.

> [!NOTE]  
> In the ```infer.py``` script, make sure this line
> ```bash
> MODEL_PATH = "src/model/qr_yolo_model_aug/weights/best.pt"
> ```
> properly points to weight ```best.pt``` generated by the model in ```src/model```


This will:  
- Load your trained YOLOv8 model  
- Run inference on all `.jpg` / `.png` images in the input folder  
- Save annotated images in `outputs/image_output/`  
- Save detection results in `outputs/submission_detection_1.json`  

Example JSON output:  
```json
[
  {
    "image_id": "image_001",
    "qrs": [
      {"bbox": [34, 45, 120, 200]}
    ]
  },
  {
    "image_id": "image_002",
    "qrs": []
  }
]
```
